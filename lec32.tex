\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage{enumitem}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[legalpaper, margin=1in]{geometry}
\setlength{\parindent}{0pt}

% Formatting commands
\newcommand{\n}{\hfill\break}
\newcommand{\lemma}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Lemma: }}\textbf{Lemma: }#1\n}
\newcommand{\defn}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Defn: }}\textbf{Defn: }#1\n}
\newcommand{\recap}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Recap: }}\textbf{Recap: }#1\n}
\newcommand{\eg}[1]{\par\noindent\settowidth{\hangindent}{\textbf{E.g.: }}\textbf{E.g.: }#1\n}
\newcommand{\thm}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Thm: }}\textbf{Thm: }#1\n}
\newcommand{\cor}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Cor: }}\textbf{Cor: }#1\n}
\newcommand{\pf}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Proof: }}\textbf{Proof: }#1\n}
\newcommand{\hw}[1]{\par\noindent\settowidth{\hangindent}{\textbf{HW: }}\textbf{HW: }#1\n}
\newcommand{\proven}{\;$\square$\n}
\newcommand{\problem}[1]{\par\noindent{#1}\n}
\newcommand{\problempart}[2]{\par\settowidth{\hangindent}{\textbf{(#1)} \indent{}}\textbf{(#1)} #2\n}
\newcommand{\ptxt}[1]{\textrm{\textnormal{#1}}}
\newcommand{\inlineeq}[1]{\n\centerline{$\displaystyle #1$}}
\newcommand{\pageline}{\noindent\rule{\textwidth}{0.1pt}\n}

% Math
\newcommand{\reals}{\mathbb{R}}
\newcommand{\R}{\reals}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\Z}{\integers}
\newcommand{\rationals}{\mathbb{Q}}
\newcommand{\Q}{\rationals}
\newcommand{\dom}{\textbf{dom}\;}
\newcommand{\epi}{\textbf{epi}\;}
\newcommand{\prob}{\textbf{prob}}
\newcommand{\ceil}{\text{ceil}}

% Probability
\newcommand{\F}{\mathcal F} 
\newcommand{\parSymbol}{\P}
\newcommand{\Prob}{\mathbb{P}}
\renewcommand{\P}{\Prob}
\newcommand{\Avg}{\mathbb{E}}
\newcommand{\E}{\Avg}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Unif}{\mathcal{U}}
\DeclareMathOperator{\Bern}{Bern}
\DeclareMathOperator{\Binom}{Binom}
\DeclareMathOperator{\Poiss}{\mathcal{P}}
\DeclareMathOperator{\Gam}{\text{Gamma}}
\DeclareMathOperator{\Exp}{\text{Exp}}
\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}

% Text
\newcommand{\tand}{\;\text{and}\;}

\title{Lecture 32}
\author{Professor Virginia R. Young\\ \small{Transcribed by Hao Chen}}
\date{December 2, 2022}

\begin{document}

\maketitle

\subsection*{5.3.4 Conditional distribution of arrival times for a $\mathcal{P}\Poiss(\lambda)$}

\defn{
\begin{align*}
    \P(T_1\leq s\mid N(t)=1)&=\frac{\P(T_1\leq s, N(t)=1)}{\P(N(t)=1)},\qquad s\leq t \\
    &=\frac{\P(N(s)=1, N(t)-N(s)=0)}{\P(N(t)=1)} \\
    &=\frac{\P(N(s)=1)\P(N(t)-N(s)=0)}{\P(N(t)=1)} \\ % TODO
    &=\frac{e^{-\lambda s}\cdot\frac{(\lambda s)^1}{1!}\cdot e^{-\lambda(t-s)}}{e^{-\lambda t}\cdot\frac{(\lambda t)^1}{1!}} \\
    &=\frac{s}{t}
\end{align*}
\[\implies T_1\mid N(t)=1\sim\Unif(0,t)\]
}

\thm{
Given that $N(t)=n$, the $n$ arrival times $S_1,\;S_2,\;\dots,\;S_n$ have the same distribution as the order statistics corresponding to $n$ iid $\Unif(0, t)$ rv's.
}

\pf{
To obtain the conditional pdf of $S_1,\;S_2,\;\dots,\;S_n$ given $N(t)=n$, note that for $0<S_1<\dots<S_n<t$, the event that $S_1=s_1$, $S_2=s_2$, $\dots$, $S_n=s_n$, $N(t)=n$, is equivalent to the event that the first $n+1$ interarrival times satisfy $T_1=s_1$, $T_2=s_2-s_1$, $\dots$, $T_n=s_n-s_{n-1}$, $T_{n+1}>t-s_n$. Thus, because the $T_i$ are iid $\Exp(\lambda)$, we have the conditional joint pdf
\begin{align*}
    f(s_1, s_2, \dots, s_n\mid N(t)=n)&=\frac{f(s_1, s_2, \dots, s_n, N(t)=n)}{\P(N(t)=0)} \\
    &=\frac{\lambda e^{-\lambda s_1}\cdot\lambda e^{-\lambda(s_2-s_1)}\dots\lambda e^{-\lambda(s_n-s_{n-1})}\cdot e^{-\lambda(t-s_n)}}{e^{-\lambda t}\cdot\frac{(\lambda t)^n}{n!}} \\
    &=\frac{n!}{t^n}, \qquad 0<s_1<\dots<s_n<t
\end{align*}
Now, $n!/t^n$ si the joint pdf of the order statistics for $n$ iid $\Unif(0, t)$ rv's. (See argument on P317)
\\\\
The joint pdf of $n$ iid $\Unif(0,t)$ rv's is $1/t^n$ on $[0,t]^n$. Each order of the $n$ rv's has probability $1/n!$ of occurring. Therefore, to scale $1/t^n$ appropriately so that it has probability mass of 1 on the set 
\[\mathcal{D}=\{(s_1, \dots, s_n)\in[0,1]^n:s_1<\dots<s_n\}\]
we have to multiply $1/t^n$ by $n!$.
\[\int_\mathcal{D}\frac{1}{t^n}\;ds_1\dots d_n=\frac{1}{n!}\implies\int_\mathcal{D}\frac{n!}{t^n}\;ds_1\dots d_n=1\]
$n$ iid rv's with common pdf $f(x)$, then the joint pdf of the order statistics is $n!(f(x))^n$.
}

\eg{
Cars pass a certain intersection according to a $\mathcal{P}\Poiss(\lambda)$. A person wants to cross the street at the location, and they wait to cross until they can see that no cars will come by in the next $T$ time units. %TODO
\\\\
(a) Find the probability that their waiting time is 0.
\[\P(N(T)=0)=e^{-\lambda T}\]
(b) Find the person's expected waiting time, $\E W$.
\begin{align*}
    \E W&=\E(\E(W\mid S_1)) \\
    &=\E(W\mid S_1>T)\P(S_1>T)+\E(W\mid S_1\leq T)\P(S_1\leq T) \\
    &=0\cdot\P(S_1>T)+\E(W\mid S_1\leq T)\P(S_1\leq T) \\
    &=(\E(S_1\mid S_1\leq T)+\E W)\cdot\P(S_1\leq T)
\end{align*}
}



\end{document}
