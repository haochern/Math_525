\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage{enumitem}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[legalpaper, margin=1in]{geometry}
\setlength{\parindent}{0pt}

% Formatting commands
\newcommand{\n}{\hfill\break}
\newcommand{\lemma}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Lemma: }}\textbf{Lemma: }#1\n}
\newcommand{\defn}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Defn: }}\textbf{Defn: }#1\n}
\newcommand{\recap}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Recap: }}\textbf{Recap: }#1\n}
\newcommand{\eg}[1]{\par\noindent\settowidth{\hangindent}{\textbf{E.g.: }}\textbf{E.g.: }#1\n}
\newcommand{\thm}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Thm: }}\textbf{Thm: }#1\n}
\newcommand{\cor}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Cor: }}\textbf{Cor: }#1\n}
\newcommand{\pf}[1]{\par\noindent\settowidth{\hangindent}{\textbf{Proof: }}\textbf{Proof: }#1\n}
\newcommand{\proven}{\;$\square$\n}
\newcommand{\problem}[1]{\par\noindent{#1}\n}
\newcommand{\problempart}[2]{\par\settowidth{\hangindent}{\textbf{(#1)} \indent{}}\textbf{(#1)} #2\n}
\newcommand{\ptxt}[1]{\textrm{\textnormal{#1}}}
\newcommand{\inlineeq}[1]{\n\centerline{$\displaystyle #1$}}
\newcommand{\pageline}{\noindent\rule{\textwidth}{0.1pt}\n}

% Math
\newcommand{\reals}{\mathbb{R}}
\newcommand{\R}{\reals}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\Z}{\integers}
\newcommand{\rationals}{\mathbb{Q}}
\newcommand{\Q}{\rationals}
\newcommand{\dom}{\textbf{dom}\;}
\newcommand{\epi}{\textbf{epi}\;}
\newcommand{\prob}{\textbf{prob}}
\newcommand{\ceil}{\text{ceil}}

% Probability
\newcommand{\F}{\mathcal F} 
\newcommand{\parSymbol}{\P}
\newcommand{\Prob}{\mathbb{P}}
\renewcommand{\P}{\Prob}
\newcommand{\Avg}{\mathbb{E}}
\newcommand{\E}{\Avg}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Unif}{Unif}
\DeclareMathOperator{\Binom}{Binom}
\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}

% Text
\newcommand{\tand}{\;\text{and}\;}

\title{Lecture 13}
\author{Professor Virginia R. Young\\ \small{Transcribed by Hao Chen}}
\date{October 3, 2022}

\begin{document}

\maketitle

\subsection*{Independent random variables}
\defn{
    $X$ and $Y$ are independent if
    \[F_{X,Y}(x,y)=F_X(x)F_Y(y), \qquad\forall x,y\in\R\]
    means the event $\{\omega\in\Omega:X(\omega)\leq x, Y(\omega)\leq y\}$ is independent with respect to $\P$ for all $x, y\in\R$.
    \\\\
    $X$ and $Y$ are independent random variables
    \[\implies\E(g(X)h(Y))=\E g(X)\cdot\E h(Y).\]
    For ex, if $X$ and $Y$ are continuous
    \[F_{X,Y}=F_X(x)F_Y(y)\]
    \begin{align*}
        F_{X,Y}(x,y)&=F_X(x)F_Y(y) \\
        \frac{\partial^2}{\partial y \partial x}\implies f_{X,Y}(x,y)&=F'_X(x)F'_Y(y) \\
        &=f_X(x)f_Y(y)
    \end{align*}
    \begin{align*}
        \implies\E(g(X)h(Y))&=\int^\infty_{-\infty}\int^\infty_{-\infty}g(x)h(y)f_X(x)f_Y(y)\;dxdy \\
        &=\int^\infty_{-\infty}g(x)f_X(x)\;dx\cdot\int^\infty_{-\infty}h(y)f_Y(y)\;dy \\
        &=\E g(X)\cdot\E h(Y)
    \end{align*}
    If $X$ and $Y$ are independent and discrete, then
    \begin{align*}
        p_{X,Y}(x,y)&=F_X(x)F_Y(y)-F_X(x)F_Y(y-)-F_X(x-)F_Y(y)+F_X(x-)F_Y(y-) \\
        &=F_X(x)(F_Y(y)-F_Y(y-))-F_X(x-)(F_Y(y)-F_Y(y-)) \\
        &=(F_X(x)-F_X(x-))(F_Y(y)-F_Y(y-)) \\
        &=p_X(x)p_Y(y)
    \end{align*}
}

\subsection*{Covariance}

\defn{
    The covariance of $X$ and $Y$ equals $\E[(X-\E X)(Y-\E Y)]$ write it as $\Cov(X,Y)$.
    \begin{align*}
        \Cov(X,Y)&=\E[XY-Y\E X-X\E Y+\E X\cdot \E Y] \\
        &=\E(XY) - \E X\cdot\E Y - \E Y\cdot\E X + \E X\cdot\E Y \\
        &=\E(XY) - \E X\E Y
    \end{align*}
    Correlation coefficient
    \[\rho_{X,Y}=\frac{\Cov(X,Y)}{\sqrt{\Var X\cdot\Var Y}}\in[-1, 1]\]
    $\rho_{X,Y}=1$ means $X\sim aY+b$, $a>0$.
}

\eg{
    Covariance of bivariate normal
    \\\\
    \[\E[(X-\E X)(Y-\E Y)]=\int_{-\infty}^\infty\int_{-\infty}^\infty (x-\mu_1)(y-\mu_2)f_{X,Y}(x,y)\;dxdy\]
    Let $z=\frac{x-\mu_1}{\sigma_1}$ and $v=\frac{x-\mu_2}{\sigma_2}$,
    \[=\int_{-\infty}^\infty\int_{-\infty}^\infty \frac{(x-\mu_1)(y-\mu_2)}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\exp{\left\{-\frac{1}{2(1-\rho^2)}\left[\left(\frac{x-\mu_1}{\sigma_1}\right)^2-2\rho\left(\frac{x-\mu_1}{\sigma_1}\right)\left(\frac{y-\mu_2}{\sigma_2}\right)+\left(\frac{y-\mu_2}{\sigma_2}\right)^2\right]\right\}}\]
    \[=\int_{-\infty}^\infty\int_{-\infty}^\infty \sigma_1z\cdot\sigma_2v\cdot\frac{1}{2\pi\sqrt{1-\rho^2}}\exp\left\{-\frac{1}{2(1-\rho^2)}\left[z^2-2\rho\cdot zv+v^2\right]\right\}\]
    \[=\int_{-\infty}^\infty\frac{\sigma_1\sigma_2v}{2\pi\sqrt{1-\rho^2}}\cdot e^{-\frac{v^2}{2(1-\rho^2)}}\cdot e^{\frac{(\rho v)^2}{2(1-\rho^2)}}\int_{-\infty}^\infty ze^{-\frac{1}{2(1-\rho^2)}(z^2-2\rho zv+(\rho v)^2)}\;dzdv\]
    \[=\frac{\sigma_1\sigma_2}{2\pi\sqrt{1-\rho^2}}\int_{-\infty}^\infty ve^{-\frac{v^2}{2}}\int_{-\infty}^\infty ze^{-\frac{1}{2(1-\rho^2)}(z-\rho v)^2}\;dzdv\]
    \[=\frac{\sigma_1\sigma_2}{\sqrt{2\pi}}\int_{-\infty}^\infty ve^{-\frac{v^2}{2}}\int_{-\infty}^\infty \frac{z}{\sqrt{2\pi(1-\rho^2)}}e^{-\frac{1}{2(1-\rho^2)}(z-\rho v)^2}\;dzdv\]
    where $\int_{-\infty}^\infty \frac{z}{\sqrt{2\pi(1-\rho^2)}}e^{-\frac{1}{2(1-\rho^2)}(z-\rho v)^2}\;dz$ is essentially the expectation of $N(\rho v, 1-\rho^2)$, which is $\rho v$. Then, 
    \[=\frac{\sigma_1\sigma_2}{\sqrt{2\pi}}\cdot\rho\int_{-\infty}^\infty v^2e^{-\frac{v^2}{2}}\;dv\]
    \[=\sigma_1\sigma_2\rho\]
    since $\int_{-\infty}^\infty \frac{v^2}{\sqrt{2\pi}}e^{-\frac{v^2}{2}}\;dv$ is equivalent to $\E(V^2)$, $V\sim N(0,1)$.
    \\\\
    Correlation coefficient
    \[\rho_{X,Y}=\frac{\Cov(X,Y)}{\sqrt{\Var X\cdot\Var Y}}=\frac{\sigma_1\sigma_2\rho}{\sqrt{\sigma_1^2\sigma_2^2}}=\rho\]
    For the bivariate normal, $X$ and $Y$ are independent iff $\rho=0$ iff $\Cov(X,Y)=0$.
    \\\\
    For other jointly distributed $X$ and $Y$, $X$ and $Y$ are independent,
    \[\implies\E(XY)=\E X\cdot\E Y\implies\Cov(X,Y)=0\]
    But if $\Cov(X,Y)=0$, then we cannot deduce that $X$ and $Y$ are independent.
}

\eg{
    Special case: $X(\omega)=1_A(\omega)$, $A\in\F$
    \[X(\omega)=\left\{\begin{array}{lc}1&\omega\in A\\0&\omega\notin A\end{array}\right.\]
    $Y=1_B$, $B\in\F$. Then, 
    \begin{align*}
        \Cov(X,Y)&=\E(XY)-\E X\cdot\E Y \\
        &=\E[1_A\cdot1_B]-\E(1_A)\E(1_B) \\
        &=\P(A\cap B)-\P(A)\P(B)
    \end{align*}
    \begin{align*}
        \Cov(X,Y)>0 &\iff \P(A\cap B)>\P(A)\P(B) \\
        &\iff \frac{\P(A\cap B)}{\P(B)}>\P(A) \\
        &\iff \P(A\mid B)>\P(A)
    \end{align*}
}

\end{document}
